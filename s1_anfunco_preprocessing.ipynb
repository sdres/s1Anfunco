{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping digit-representations in the human primary somatosensory cortex and their layer-dependent functional connectivity at 7T.\n",
    "## Preprocessing\n",
    "\n",
    "In this notebook, we are describing and, where possible, performing the preprocessing of this publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import nistats\n",
    "import nilearn\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import stats\n",
    "from nilearn import plotting\n",
    "from scipy import ndimage\n",
    "import matplotlib.cm as cm\n",
    "import ants\n",
    "import os\n",
    "\n",
    "from scipy.ndimage import morphology\n",
    "from nibabel import load, save, Nifti1Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locating the data\n",
    "\n",
    "Because the data location will be different for every machine, we will first define a root folder that we will use from then on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/media/sebastian/Data/S1ANFUNCO/raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this folder, we will find the find the DICOMs, the nifti data in BIDS format in the \"S1ANFUNCO_BIDS\" folder and the derivatives folder, which will contain our processed data and analyses.\n",
    "\n",
    "\n",
    "Next, we can make a list of participant-identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subFolders = sorted(glob.glob(root + '/S1ANFUNCO_BIDS/sub*'))\n",
    "subs = [i[-6:] for i in subFolders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessFolders = sorted(glob.glob(root + '/S1ANFUNCO_BIDS/sub*/*'))\n",
    "sessFolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comes to mind immediately are the participant and session numbers. When scanning the first 5 subjects, we tested different imaging-parameters and stimulation protocols. Therefore, the subjects are either not included or were reinvited for at a later time. Hence, the higher session numbers in sub-2 and sub-05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the derivatives folder, we will have to make a new folder for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"$root\"\n",
    "\n",
    "for sub in $1\n",
    "do\n",
    "mkdir $2/derivatives/$sub\n",
    "mkdir $2/derivatives/$sub/anat\n",
    "mkdir $2/derivatives/$sub/func\n",
    "mkdir $2/derivatives/$sub/func/rest\n",
    "mkdir $2/derivatives/$sub/func/stim\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion correction\n",
    "\n",
    "To account for non-linear distortions due to low bandwidth, a manually drawn motion mask covering the postcentral gyrus was used to optimize registration on our target region. Mask selection was guided by the raw EPI data and they can be inspected in the derivatives folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionMasks = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/sub-*_moma.nii'))\n",
    "restRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-restBA3b_run-001_cbv.nii.gz'))\n",
    "\n",
    "for restRun, motionMask in zip(restRuns,motionMasks):\n",
    "\n",
    "    underlay = nb.load(restRun).get_fdata()[:,:,:,0]\n",
    "    \n",
    "    display = plotting.plot_roi(motionMask, underlay, display_mode='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resting state\n",
    "\n",
    "For each subject, we want to register all runs to the resting state data. Therefore, we will first do the motion correction for those.\n",
    "\n",
    "To loop properly in bash, I need to create various lists in python first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subFolders = sorted(glob.glob(root + '/S1ANFUNCO_BIDS/sub*'))\n",
    "subs = [i[-6:] for i in subFolders]\n",
    "restRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-restBA3b_run-001_cbv.nii.gz'))\n",
    "motionMasks = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/sub-*_moma.nii'))\n",
    "outFolders =  sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/func/rest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"{\" \".join(restRuns)}\" \"{\" \".join(motionMasks)}\" \"{\" \".join(outFolders)}\"\n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "List3=$3\n",
    "List4=$4\n",
    "\n",
    "subsList=($List1)\n",
    "restRunsList=($List2)\n",
    "momaList=($List3)\n",
    "outFolders=($List4)\n",
    "\n",
    "len=${#subsList[@]}\n",
    " \n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "base=${subsList[$j]}_rest3b_run-001\n",
    "outFolder=${outFolders[$j]}\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The resting-state data is: ${restRunsList[$j]}\n",
    "echo The motion mask is: ${momaList[$j]}\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #\n",
    "\n",
    "cd ${outFolder}\n",
    "\n",
    "\n",
    "###########################################\n",
    "###### parameters that are not used  ######\n",
    "###########################################\n",
    "\n",
    "ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=8\n",
    "export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS\n",
    "tr=1\n",
    "basevol=1000 # ANTs indexing\n",
    "\n",
    "mkdir -p motionParameters/run-001/nn_motion\n",
    "mkdir -p motionParameters/run-001/n_motion\n",
    "\n",
    "\n",
    "###########################################\n",
    "####### preparig odd and even images ######\n",
    "###########################################\n",
    "\n",
    "#for classical Magentom VASO sequences\n",
    "3dcalc -a ${restRunsList[$j]}'[0..$(2)]' -expr 'a' -prefix ${base}_notnulled.nii -overwrite\n",
    "3dcalc -a ${restRunsList[$j]}'[1..$(2)]' -expr 'a' -prefix ${base}_nulled.nii -overwrite\n",
    "\n",
    "# for Terra 7T VASO sequence\n",
    "#3dcopy $1'[0..$(2)]' nulled.nii\n",
    "#3dcopy $1'[1..$(2)]' notnulled.nii\n",
    "\n",
    "\n",
    "# 3dAutomask -prefix moma.nii -peels 3 -dilate 2  notnulled.nii\n",
    "\n",
    "###########################################\n",
    "####### Do MOCO on notnulled  #############\n",
    "###########################################\n",
    "\n",
    "n_vols=`PrintHeader ${base}_notnulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "\n",
    "echo \"seperating $n_vols time steps to save RAM\"\n",
    "ImageMath 4 vol_.nii TimeSeriesDisassemble ${base}_notnulled.nii # vol_1000.nii, vol_1001.nii ...\n",
    "cp vol_1003.nii vol_1000.nii # removing steady state effects\n",
    "cp vol_1004.nii vol_1001.nii\n",
    "cp vol_1005.nii vol_1002.nii\n",
    "3dMean -prefix ${base}_nn_reference.nii vol_1004.nii vol_1005.nii # there is no overwrite here, in case of multiple series\n",
    "nthvol=$(($basevol + $n_vols - 1)) # Zero indexing\n",
    "echo \"doing the alignemt\"\n",
    "for i in $(eval echo \"{$basevol..$nthvol}\");\n",
    "do\n",
    "antsRegistration \\\n",
    "--dimensionality 3 \\\n",
    "--float 1 \\\n",
    "--collapse-output-transforms 1 \\\n",
    "--output [ vol_${i}_,vol_${i}_Warped.nii.gz,vol_${i}_InverseWarped.nii.gz ] \\\n",
    "--interpolation BSpline[2] \\\n",
    "--use-histogram-matching 1 \\\n",
    "--winsorize-image-intensities [ 0.005,0.995 ] \\\n",
    "-x ${momaList[$i]} \\\n",
    "--initial-moving-transform [ ${base}_nn_reference.nii,vol_${i}.nii,1 ] \\\n",
    "--transform Rigid[ 0.1 ] \\\n",
    "--metric MI[ ${base}_nn_reference.nii,vol_${i}.nii,1,32,Regular,0.25 ] \\\n",
    "--convergence [ 250x100,1e-6,10 ] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox\n",
    "#--transform SyN[ 0.1,3,0 ] \\\n",
    "#--metric CC[ nn_reference.nii,vol_${i}.nii,1,4 ] \\\n",
    "#--convergence [ 50x0,1e-6,10 ] \\\n",
    "#--shrink-factors 2x1 \\\n",
    "#--smoothing-sigmas 1x0vox\n",
    "done\n",
    "\n",
    "echo \"reassembling the time points\"\n",
    "ImageMath 4 ${base}_moco_notnulled.nii TimeSeriesAssemble $tr 0 vol_*_Warped.nii.gz\n",
    "mv vol_*.nii motionParameters/run-001/nn_motion\n",
    "mv vol_*_0GenericAffine.mat motionParameters/run-001/nn_motion\n",
    "mv vol_*_InverseWarped.nii.gz motionParameters/run-001/nn_motion\n",
    "mv vol_*_Warped.nii.gz motionParameters/run-001/nn_motion\n",
    "\n",
    "\n",
    "###########################################\n",
    "####### Do MOCO on nulled  ################\n",
    "###########################################\n",
    "\n",
    "n_vols=`PrintHeader ${base}_nulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "\n",
    "echo \"seperating $n_vols time steps to save RAM\"\n",
    "ImageMath 4 vol_.nii TimeSeriesDisassemble ${base}_nulled.nii # vol_1000.nii, vol_1001.nii ...\n",
    "cp vol_1003.nii vol_1000.nii # removing steady state effects\n",
    "cp vol_1004.nii vol_1001.nii\n",
    "cp vol_1005.nii vol_1002.nii\n",
    "3dMean -prefix ${base}_n_reference.nii vol_1004.nii vol_1005.nii # there is no overwrite here, in case of multiple series\n",
    "nthvol=$(($basevol + $n_vols - 1)) # Zero indexing\n",
    "echo \"doing the alignemt\"\n",
    "for i in $(eval echo \"{$basevol..$nthvol}\");\n",
    "do\n",
    "antsRegistration \\\n",
    "--dimensionality 3 \\\n",
    "--float 1 \\\n",
    "--collapse-output-transforms 1 \\\n",
    "--output [ vol_${i}_,vol_${i}_Warped.nii.gz,vol_${i}_InverseWarped.nii.gz ] \\\n",
    "--interpolation BSpline[2] \\\n",
    "--use-histogram-matching 1 \\\n",
    "--winsorize-image-intensities [ 0.005,0.995 ] \\\n",
    "-x ${momaList[$i]} \\\n",
    "--initial-moving-transform [ ${base}_n_reference.nii,vol_${i}.nii,1 ] \\\n",
    "--transform Rigid[ 0.1 ] \\\n",
    "--metric MI[ ${base}_n_reference.nii,vol_${i}.nii,1,32,Regular,0.25 ] \\\n",
    "--convergence [ 250x100,1e-6,10 ] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox\n",
    "#--transform SyN[ 0.1,3,0 ] \\\n",
    "#--metric CC[ n_reference.nii,vol_${i}.nii,1,4 ] \\\n",
    "#--convergence [ 50x0,1e-6,10 ] \\\n",
    "#--shrink-factors 2x1 \\\n",
    "#--smoothing-sigmas 1x0voxdone\n",
    "done\n",
    "echo \"reassembling the time points\"\n",
    "ImageMath 4 ${base}_moco_nulled.nii TimeSeriesAssemble $tr 0 vol_*_Warped.nii.gz\n",
    "mv vol_*.nii motionParameters/run-001/n_motion\n",
    "mv vol_*_0GenericAffine.mat motionParameters/run-001/n_motion\n",
    "mv vol_*_Warped.nii.gz motionParameters/run-001/n_motion\n",
    "mv vol_*_InverseWarped.nii.gz motionParameters/run-001/n_motion\n",
    "\n",
    "\n",
    "##############################\n",
    "#### fsl_motion_outliers  ####\n",
    "##############################\n",
    "\n",
    "fsl_motion_outliers -i ${base}_nulled.nii -o motionParameters/run-001/${base}_nulled_confounds.txt\n",
    "fsl_motion_outliers -i ${base}_notnulled.nii -o motionParameters/run-001/${base}_notnulled_confounds.txt\n",
    "\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulation \n",
    "\n",
    "After the motion correction is completed for the resting state data, we can use the reference images for the stimulation data. However, we have to take care here, because some participants underwent multiple runs of stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stimRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-stim*_cbv.nii.gz'))\n",
    "runNumberList = [i[-18:-11] for i in stimRuns]\n",
    "subList = [i[-43:-37] for i in stimRuns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subList)}\" \"{\" \".join(stimRuns)}\" \"{\" \".join(runNumberList)}\" \n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "List3=$3\n",
    "\n",
    "subsList=($List1)\n",
    "stimRunsList=($List2)\n",
    "runNumberList=($List3)\n",
    "\n",
    "len=${#subsList[@]}\n",
    " \n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "base=${subsList[$j]}_stim_${runNumberList[$j]}\n",
    "outFolder=/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/${subsList[$j]}/func/stim\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The current stimulation run is: ${stimRunsList[$j]}\n",
    "echo The motion mask is: /media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/${subsList[$j]}/${subsList[$j]}_moma.nii\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #\n",
    "\n",
    "\n",
    "cd ${outFolder}\n",
    "\n",
    "\n",
    "###########################################\n",
    "###### parameters that are not used  ######\n",
    "###########################################\n",
    "\n",
    "ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=8\n",
    "export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS\n",
    "tr=1\n",
    "basevol=1000 # ANTs indexing\n",
    "\n",
    "mkdir -p motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mkdir -p motionParameters/${runNumberList[$j]}/n_motion\n",
    "\n",
    "\n",
    "###########################################\n",
    "####### preparig odd and even images ######\n",
    "###########################################\n",
    "\n",
    "#for classical Magentom VASO sequences\n",
    "3dcalc -a ${stimRunsList[$j]}'[0..$(2)]' -expr 'a' -prefix ${base}_notnulled.nii -overwrite\n",
    "3dcalc -a ${stimRunsList[$j]}'[1..$(2)]' -expr 'a' -prefix ${base}_nulled.nii -overwrite\n",
    "\n",
    "\n",
    "###########################################\n",
    "####### Do MOCO on notnulled  #############\n",
    "###########################################\n",
    "\n",
    "n_vols=`PrintHeader ${base}_notnulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "\n",
    "echo \"seperating $n_vols time steps to save RAM\"\n",
    "ImageMath 4 vol_.nii TimeSeriesDisassemble ${base}_notnulled.nii # vol_1000.nii, vol_1001.nii ...\n",
    "cp vol_1003.nii vol_1000.nii # removing steady state effects\n",
    "cp vol_1004.nii vol_1001.nii\n",
    "cp vol_1005.nii vol_1002.nii\n",
    "nthvol=$(($basevol + $n_vols - 1)) # Zero indexing\n",
    "echo \"doing the alignemt\"\n",
    "for i in $(eval echo \"{$basevol..$nthvol}\");\n",
    "do\n",
    "antsRegistration \\\n",
    "--dimensionality 3 \\\n",
    "--float 1 \\\n",
    "--collapse-output-transforms 1 \\\n",
    "--output [ vol_${i}_,vol_${i}_Warped.nii.gz,vol_${i}_InverseWarped.nii.gz ] \\\n",
    "--interpolation BSpline[2] \\\n",
    "--use-histogram-matching 1 \\\n",
    "--winsorize-image-intensities [ 0.005,0.995 ] \\\n",
    "-x ${momaList[$i]} \\\n",
    "--initial-moving-transform [ ../rest/${subsList[$j]}_rest3b_run-001_nn_reference.nii,vol_${i}.nii,1 ] \\\n",
    "--transform Rigid[ 0.1 ] \\\n",
    "--metric MI[ ../rest/${subsList[$j]}_rest3b_run-001_nn_reference.nii,vol_${i}.nii,1,32,Regular,0.25 ] \\\n",
    "--convergence [ 250x100,1e-6,10 ] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox\n",
    "#--transform SyN[ 0.1,3,0 ] \\\n",
    "#--metric CC[ nn_reference.nii,vol_${i}.nii,1,4 ] \\\n",
    "#--convergence [ 50x0,1e-6,10 ] \\\n",
    "#--shrink-factors 2x1 \\\n",
    "#--smoothing-sigmas 1x0vox\n",
    "done\n",
    "\n",
    "echo \"reassembling the time points\"\n",
    "ImageMath 4 ${base}_moco_notnulled.nii TimeSeriesAssemble $tr 0 vol_*_Warped.nii.gz\n",
    "mv vol_*.nii motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mv vol_*_0GenericAffine.mat motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mv vol_*_1Warp.nii.gz motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mv vol_*_1InverseWarp.nii.gz motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mv vol_*_InverseWarped.nii.gz motionParameters/${runNumberList[$j]}/nn_motion\n",
    "mv vol_*_Warped.nii.gz motionParameters/${runNumberList[$j]}/nn_motion\n",
    "\n",
    "\n",
    "###########################################\n",
    "####### Do MOCO on nulled  ################\n",
    "###########################################\n",
    "\n",
    "n_vols=`PrintHeader ${base}_nulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "\n",
    "echo \"seperating $n_vols time steps to save RAM\"\n",
    "ImageMath 4 vol_.nii TimeSeriesDisassemble ${base}_nulled.nii # vol_1000.nii, vol_1001.nii ...\n",
    "cp vol_1003.nii vol_1000.nii # removing steady state effects\n",
    "cp vol_1004.nii vol_1001.nii\n",
    "cp vol_1005.nii vol_1002.nii\n",
    "nthvol=$(($basevol + $n_vols - 1)) # Zero indexing\n",
    "echo \"doing the alignemt\"\n",
    "for i in $(eval echo \"{$basevol..$nthvol}\");\n",
    "do\n",
    "antsRegistration \\\n",
    "--dimensionality 3 \\\n",
    "--float 1 \\\n",
    "--collapse-output-transforms 1 \\\n",
    "--output [ vol_${i}_,vol_${i}_Warped.nii.gz,vol_${i}_InverseWarped.nii.gz ] \\\n",
    "--interpolation BSpline[2] \\\n",
    "--use-histogram-matching 1 \\\n",
    "--winsorize-image-intensities [ 0.005,0.995 ] \\\n",
    "-x ${momaList[$i]} \\\n",
    "--initial-moving-transform [ ../rest/${subsList[$j]}_rest3b_run-001_n_reference.nii,vol_${i}.nii,1 ] \\\n",
    "--transform Rigid[ 0.1 ] \\\n",
    "--metric MI[ ../rest/${subsList[$j]}_rest3b_run-001_n_reference.nii,vol_${i}.nii,1,32,Regular,0.25 ] \\\n",
    "--convergence [ 250x100,1e-6,10 ] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox\n",
    "#--transform SyN[ 0.1,3,0 ] \\\n",
    "#--metric CC[ n_reference.nii,vol_${i}.nii,1,4 ] \\\n",
    "#--convergence [ 50x0,1e-6,10 ] \\\n",
    "#--shrink-factors 2x1 \\\n",
    "#--smoothing-sigmas 1x0voxdone\n",
    "done\n",
    "echo \"reassembling the time points\"\n",
    "ImageMath 4 ${base}_moco_nulled.nii TimeSeriesAssemble $tr 0 vol_*_Warped.nii.gz\n",
    "mv vol_*.nii motionParameters/${runNumberList[$j]}/n_motion\n",
    "mv vol_*_0GenericAffine.mat motionParameters/${runNumberList[$j]}/n_motion\n",
    "mv vol_*_Warped.nii.gz motionParameters/${runNumberList[$j]}/n_motion\n",
    "mv vol_*__InverseWarped.nii.gz motionParameters/${runNumberList[$j]}/n_motion\n",
    "mv vol_*_InverseWarped.nii.gz motionParameters/${runNumberList[$j]}/n_motion\n",
    "mv vol_*_Warped.nii.gz motionParameters/${runNumberList[$j]}/n_motion\n",
    "\n",
    "\n",
    "##############################\n",
    "#### fsl_motion_outliers  ####\n",
    "##############################\n",
    "\n",
    "fsl_motion_outliers -i ${base}_nulled.nii -o motionParameters/${runNumberList[$j]}/${base}_nulled_confounds.txt\n",
    "fsl_motion_outliers -i ${base}_notnulled.nii -o motionParameters/${runNumberList[$j]}/${base}_notnulled_confounds.txt\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "#### Temporal upsampling so VASO matches BOLD ####\n",
    "##################################################\n",
    "\n",
    "echo \"temporal upsampling and shifting happens now\"\n",
    "3dUpsample -overwrite  -datum short -prefix ${base}_Nulled_intemp.nii -n 2 -input ${base}_moco_nulled.nii\n",
    "3dUpsample -overwrite  -datum short -prefix ${base}_BOLD_intemp.nii   -n 2 -input ${base}_moco_notnulled.nii\n",
    "\n",
    "##for Magentom clasical VASO sequence\n",
    "NumVol=`3dinfo -nv ${base}_Nulled_intemp.nii`\n",
    "3dTcat -overwrite -prefix ${base}_Nulled_intemp.nii ${base}_Nulled_intemp.nii'[0]' ${base}_Nulled_intemp.nii'[0..'`expr $NumVol - 2`']'\n",
    "\n",
    "echo \"I am correcting for the proper TR in the header\"\n",
    "3drefit -TR 1.9295 ${base}_BOLD_intemp.nii\n",
    "3drefit -TR 1.9295 ${base}_Nulled_intemp.nii\n",
    "\n",
    "echo \"BOLD correction happens now\"\n",
    "LN_BOCO -Nulled ${base}_Nulled_intemp.nii -BOLD ${base}_BOLD_intemp.nii -output ${base}\n",
    "\n",
    "\n",
    "echo \"curtosis and skew\"\n",
    "LN_SKEW -input ${base}_BOLD_intemp.nii\n",
    "LN_SKEW -input ${base}_VASO_LN.nii\n",
    "\n",
    "# The FSL GLM does not seem to like images where values are between 0 and 1. There fore, we are multipolying everything by 100.\n",
    "fslmaths ${base}_VASO_LN.nii -mul 100 ${base}_VASO_LN_short.nii -odt short\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion-Parameters\n",
    "\n",
    "Here, we want to get the motion-parameters in FSL-format\n",
    "\n",
    "in the command line, this would work with the following command:\n",
    "\n",
    "    \"avscale --allparams ./vol_1000_0GenericAffine_FSL.mat ./vol_1000.nii'\"\n",
    "\n",
    "Which, next to other things, gives this\n",
    "\n",
    "    Rotation Angles (x,y,z) [rads] = -0.005394 -0.001896 0.000310 \n",
    "\n",
    "    Translations (x,y,z) [mm] = 0.014202 0.002413 0.003689 \n",
    "\n",
    "\n",
    "However, we want to neatly do this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subFolders = sorted(glob.glob(root + '/S1ANFUNCO_BIDS/sub*'))\n",
    "subs = [i[-6:] for i in subFolders]\n",
    "restRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-restBA3b_run-001_cbv.nii.gz'))\n",
    "motionMasks = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/sub-*_moma.nii'))\n",
    "outFolders =  sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/func/rest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"{\" \".join(restRuns)}\" \"{\" \".join(motionMasks)}\" \"{\" \".join(outFolders)}\"\n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "List3=$3\n",
    "List4=$4\n",
    "\n",
    "subsList=($List1)\n",
    "restRunsList=($List2)\n",
    "momaList=($List3)\n",
    "outFolders=($List4)\n",
    "\n",
    "len=${#subsList[@]}\n",
    "\n",
    "\n",
    "\n",
    "imageTypes=(\"n\" \"nn\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "# base=${subsList[$j]}_rest3b\n",
    "base=${subsList[$j]}_rest3b_run-001\n",
    "outFolder=${outFolders[$j]}\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #\n",
    "\n",
    "cd ${outFolder}\n",
    "\n",
    "n_vols=`PrintHeader ${base}_notnulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "num=$((n_vols + 1000))\n",
    "\n",
    "echo $num\n",
    "\n",
    "for imageType in \"${imageTypes[@]}\"\n",
    "do\n",
    "\n",
    "\n",
    "for (( k=1000; k<$num; k++ ))\n",
    "do\n",
    "ConvertTransformFile \\\n",
    "3 \\\n",
    "''${outFolder}'/motionParameters/run-001/'$imageType'_motion/vol_'$k'_0GenericAffine.mat' \\\n",
    "''${outFolder}'/motionParameters/run-001/'$imageType'_motion/vol_'$k'_0GenericAffine_af.mat' \\\n",
    "--convertToAffineType\n",
    "\n",
    "\n",
    "c3d_affine_tool \\\n",
    "-ref ''${subsList[$j]}'_rest3b_run-001_n_reference.nii' \\\n",
    "-src ''${outFolder}'/motionParameters/run-001/'$imageType'_motion/vol_'$k'.nii' \\\n",
    "-itk ''${outFolder}'/motionParameters/run-001/'$imageType'_motion/vol_'$k'_0GenericAffine_af.mat' -ras2fsl \\\n",
    "-o ''${outFolder}'/motionParameters/run-001/'$imageType'_motion/vol_'$k'_0GenericAffine_FSL.mat' \\\n",
    "-info-full\n",
    "done\n",
    "\n",
    "done\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.interfaces.fsl as fsl\n",
    "import itertools\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsubMot  = []\n",
    "lstsubMot_Nme  = []\n",
    "lstTR_sub = []\n",
    "sub_list =[]\n",
    "modalityList = []\n",
    "\n",
    "modalities = [\"n\", 'nn']\n",
    "modalitiesDict = {'n': 'VASO', 'nn': 'BOLD'}\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    \n",
    "    for modality in modalities:\n",
    "        \n",
    "        print(sub)\n",
    "        affinemats = sorted(glob.glob(root + f'/derivatives/{sub}/func/rest/motionParameters/run-001/{modality}_motion/vol_*_0GenericAffine_FSL.mat'))\n",
    "        print(len(affinemats))\n",
    "\n",
    "        volids=[]\n",
    "        for n in range(len(affinemats)):\n",
    "            volids.append(n+1000)\n",
    "\n",
    "        for volid in volids:\n",
    "\n",
    "            # Current mats\n",
    "            currMats = root + f'/derivatives/{sub}/func/rest/motionParameters/run-001/{modality}_motion/vol_{volid}_0GenericAffine_FSL.mat'\n",
    "\n",
    "            tmp = fsl.AvScale(all_param=True,mat_file=currMats)\n",
    "\n",
    "            tmpReadout = tmp.run()\n",
    "\n",
    "            # Get the rotations (in rads) and translations (in mm) per volume\n",
    "\n",
    "            aryTmpMot = list(itertools.chain.from_iterable(\n",
    "                                        [tmpReadout.outputs.translations,\n",
    "                                         tmpReadout.outputs.rot_angles]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Save the roation and translations\n",
    "            lstsubMot.append(aryTmpMot)\n",
    "            lstTR_sub.append([int(volid)+1-1000 for i in range(6)])               \n",
    "            lstsubMot_Nme.append([f'TX {modalitiesDict[modality]}',f'TY {modalitiesDict[modality]}',f'TZ {modalitiesDict[modality]}',f'RX {modalitiesDict[modality]}',f'RY {modalitiesDict[modality]}',f'RZ {modalitiesDict[modality]}'])\n",
    "            sub_list.append([str(sub) for i in range(6)])\n",
    "            modalityList.append([str(modalitiesDict[modality]) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aryCurr = np.array(lstsubMot)\n",
    "aryCurr_Ses =  aryCurr.reshape((aryCurr.size,-1))\n",
    "aryCurr_TR = np.array(lstTR_sub)\n",
    "aryCurr_TR_Ses = aryCurr_TR.reshape((aryCurr_TR.size,-1))\n",
    "aryCurr_Nme = np.array(lstsubMot_Nme)\n",
    "aryCurr_Nme_Ses = aryCurr_Nme.reshape((aryCurr_Nme.size,-1))\n",
    "aryIdx = np.arange(1,len(aryCurr_Nme_Ses)+1)\n",
    "\n",
    "aryCurr_mod = np.array(modalityList)\n",
    "aryCurr_mod = aryCurr_mod.reshape((aryCurr_mod.size,-1))\n",
    "\n",
    "aryCurr_subname = np.array(sub_list)\n",
    "aryCurr_subs =  aryCurr_subname.reshape((aryCurr_subname.size,-1))\n",
    "     \n",
    "data_dict = {\n",
    "    'subject': aryCurr_subs[:,0],\n",
    "    'Time/TR': aryCurr_TR_Ses[:,0],\n",
    "    'Motion_Name': aryCurr_Nme_Ses[:,0],\n",
    "    'Motion': aryCurr_Ses[:,0],\n",
    "    'idx':aryIdx,\n",
    "    'modality': aryCurr_mod[:,0]}\n",
    "    \n",
    "pd_ses = pd.DataFrame(data=data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ses.to_csv('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/quality_assessmen/motionParametersRest.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-stim*_cbv.nii.gz'))\n",
    "runNumberList = [i[-18:-11] for i in stimRuns]\n",
    "subList = [i[-43:-37] for i in stimRuns]\n",
    "outFolders =  sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/func/stim/motionParameters/run-00*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subList)}\" \"{\" \".join(stimRuns)}\" \"{\" \".join(runNumberList)}\" \"{\" \".join(outFolders)}\"\n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "List3=$3\n",
    "List4=$4\n",
    "\n",
    "subsList=($List1)\n",
    "stimRunsList=($List2)\n",
    "runNumberList=($List3)\n",
    "outFolders=($List4)\n",
    "\n",
    "len=${#subsList[@]}\n",
    "\n",
    "\n",
    "\n",
    "imageTypes=(\"n\" \"nn\")\n",
    "\n",
    "len=${#subsList[@]}\n",
    " \n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "base=${subsList[$j]}_stim_${runNumberList[$j]}\n",
    "outFolder=${outFolders[$j]}\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The current stimulation run is: ${stimRunsList[$j]}\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #\n",
    "\n",
    "cd ${outFolder}\n",
    "\n",
    "n_vols=`PrintHeader ../../${base}_notnulled.nii | grep Dimens | cut -d ',' -f 4 | cut -d ']' -f 1`\n",
    "num=$((n_vols + 1000))\n",
    "\n",
    "echo $num\n",
    "\n",
    "for imageType in \"${imageTypes[@]}\"\n",
    "do\n",
    "\n",
    "\n",
    "for (( k=1000; k<$num; k++ ))\n",
    "do\n",
    "ConvertTransformFile \\\n",
    "3 \\\n",
    "''$imageType'_motion/vol_'$k'_0GenericAffine.mat' \\\n",
    "''$imageType'_motion/vol_'$k'_0GenericAffine_af.mat' \\\n",
    "--convertToAffineType\n",
    "\n",
    "\n",
    "c3d_affine_tool \\\n",
    "-ref '../../../rest/'${subsList[$j]}'_rest3b_run-001_'$imageType'_reference.nii' \\\n",
    "-src ''$imageType'_motion/vol_'$k'.nii' \\\n",
    "-itk ''$imageType'_motion/vol_'$k'_0GenericAffine_af.mat' -ras2fsl \\\n",
    "-o ''$imageType'_motion/vol_'$k'_0GenericAffine_FSL.mat' \\\n",
    "-info-full\n",
    "done\n",
    "\n",
    "done\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimRuns = sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-stim*_cbv.nii.gz'))\n",
    "runNumberList = [i[-18:-11] for i in stimRuns]\n",
    "subList = [i[-43:-37] for i in stimRuns]\n",
    "outFolders =  sorted(glob.glob('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-*/func/stim/motionParameters/run-00*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsubMot  = []\n",
    "lstsubMot_Nme  = []\n",
    "lstTR_sub = []\n",
    "sub_list =[]\n",
    "modalityList = []\n",
    "runsList = []\n",
    "\n",
    "modalities = [\"n\", 'nn']\n",
    "modalitiesDict = {'n': 'VASO', 'nn': 'BOLD'}\n",
    "\n",
    "\n",
    "for sub in subList:\n",
    "    for run in runNumberList:\n",
    "\n",
    "        for modality in modalities:\n",
    "\n",
    "            print(sub)\n",
    "            affinemats = sorted(glob.glob(root + f'/derivatives/{sub}/func/stim/motionParameters/{run}/{modality}_motion/vol_*_0GenericAffine_FSL.mat'))\n",
    "            print(len(affinemats))\n",
    "\n",
    "            volids=[]\n",
    "            for n in range(len(affinemats)):\n",
    "                volids.append(n+1000)\n",
    "\n",
    "            for volid in volids:\n",
    "\n",
    "                # Current mats\n",
    "                currMats = root + f'/derivatives/{sub}/func/stim/motionParameters/{run}/{modality}_motion/vol_{volid}_0GenericAffine_FSL.mat'\n",
    "\n",
    "                tmp = fsl.AvScale(all_param=True,mat_file=currMats)\n",
    "\n",
    "                tmpReadout = tmp.run()\n",
    "\n",
    "                # Get the rotations (in rads) and translations (in mm) per volume\n",
    "\n",
    "                aryTmpMot = list(itertools.chain.from_iterable(\n",
    "                                            [tmpReadout.outputs.translations,\n",
    "                                             tmpReadout.outputs.rot_angles]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Save the roation and translations\n",
    "                lstsubMot.append(aryTmpMot)\n",
    "                lstTR_sub.append([int(volid)+1-1000 for i in range(6)])               \n",
    "                lstsubMot_Nme.append([f'TX {modalitiesDict[modality]}',f'TY {modalitiesDict[modality]}',f'TZ {modalitiesDict[modality]}',f'RX {modalitiesDict[modality]}',f'RY {modalitiesDict[modality]}',f'RZ {modalitiesDict[modality]}'])\n",
    "                sub_list.append([str(sub) for i in range(6)])\n",
    "                modalityList.append([str(modalitiesDict[modality]) for i in range(6)])\n",
    "                runsList.append([str(run) for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aryCurr = np.array(lstsubMot)\n",
    "aryCurr_Ses =  aryCurr.reshape((aryCurr.size,-1))\n",
    "aryCurr_TR = np.array(lstTR_sub)\n",
    "aryCurr_TR_Ses = aryCurr_TR.reshape((aryCurr_TR.size,-1))\n",
    "aryCurr_Nme = np.array(lstsubMot_Nme)\n",
    "aryCurr_Nme_Ses = aryCurr_Nme.reshape((aryCurr_Nme.size,-1))\n",
    "aryIdx = np.arange(1,len(aryCurr_Nme_Ses)+1)\n",
    "\n",
    "aryCurr_mod = np.array(modalityList)\n",
    "aryCurr_mod = aryCurr_mod.reshape((aryCurr_mod.size,-1))\n",
    "\n",
    "aryCurr_subname = np.array(sub_list)\n",
    "aryCurr_subs =  aryCurr_subname.reshape((aryCurr_subname.size,-1))\n",
    "     \n",
    "data_dict = {\n",
    "    'subject': aryCurr_subs[:,0],\n",
    "    'Time/TR': aryCurr_TR_Ses[:,0],\n",
    "    'Motion_Name': aryCurr_Nme_Ses[:,0],\n",
    "    'Motion': aryCurr_Ses[:,0],\n",
    "    'idx':aryIdx,\n",
    "    'modality': aryCurr_mod[:,0]}\n",
    "    \n",
    "pd_ses = pd.DataFrame(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on sub-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_lim = ['sub-02']\n",
    "\n",
    "for sub in subs_lim:\n",
    "    pd_ses_rot_VASO = pd_ses.loc[(pd_ses['Motion_Name'].str.contains(\"R\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']=='VASO')].dropna()\n",
    "    pd_ses_trans_VASO = pd_ses.loc[(pd_ses['Motion_Name'].str.contains(\"T\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']=='VASO')].dropna()\n",
    "    \n",
    "    pd_ses_rot_BOLD = pd_ses.loc[(pd_ses['Motion_Name'].str.contains(\"R\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']=='BOLD')].dropna()\n",
    "    pd_ses_trans_BOLD = pd_ses.loc[(pd_ses['Motion_Name'].str.contains(\"T\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']=='BOLD')].dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1,sharex=True,figsize=(20,12))\n",
    "plt.suptitle('%s Motion Summary [T:mm / R: Rads]'%(sub))\n",
    "\n",
    "\n",
    "sns.lineplot(ax=axes[0], x='Time/TR',y='Motion',data=pd_ses_trans_VASO,hue='Motion_Name', palette = 'Set1')\n",
    "sns.lineplot(ax=axes[0], x='Time/TR',y='Motion',data=pd_ses_trans_BOLD,hue='Motion_Name', palette = 'Set2')\n",
    "\n",
    "\n",
    "axes[0].set_ylabel(\"translation (mm)\")\n",
    "\n",
    "\n",
    "sns.lineplot(ax=axes[1], x='Time/TR',y='Motion',data=pd_ses_rot_VASO,hue='Motion_Name', palette = 'Set1')\n",
    "sns.lineplot(ax=axes[1], x='Time/TR',y='Motion',data=pd_ses_rot_BOLD,hue='Motion_Name', palette = 'Set2')\n",
    "\n",
    "\n",
    "\n",
    "axes[1].set_ylabel(\"rotation (radians)\")\n",
    "plt.savefig('/home/sebastian/Desktop/%s_motion.jpg'%(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assessment\n",
    "\n",
    "Especially in high resolution fMRI, rigurous quality controls are necessary to evaulate the data. In the following we will go through various procedures to give a rough estimate of the data-quality.\n",
    "\n",
    "- Mean image\n",
    "- TSNR\n",
    "- skew\n",
    "- kurtosis\n",
    "- FD\n",
    "- Motion assessment a la Marquardt\n",
    "\n",
    "For some of these measures, we have to do a bit more processing. Therefore, I will first continue with the steps outlined in Renzo's BOLD-correction scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# include how I found correct TR!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"{\" \".join(outFolders)}\"\n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "\n",
    "subsList=($List1)\n",
    "outFolders=($List2)\n",
    "\n",
    "\n",
    "len=${#subsList[@]}\n",
    "\n",
    "\n",
    "imageTypes=(\"n\" \"nn\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "# base=${subsList[$j]}_rest3b\n",
    "base=${subsList[$j]}_rest3b_run-001\n",
    "outFolder=${outFolders[$j]}\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #\n",
    "\n",
    "cd ${outFolder}\n",
    "\n",
    "\n",
    "##################################################\n",
    "#### Temporal upsampling so VASO matches BOLD ####\n",
    "##################################################\n",
    "\n",
    "echo \"temporal upsampling and shifting happens now\"\n",
    "3dUpsample -overwrite  -datum short -prefix ${base}_Nulled_intemp.nii -n 2 -input ${base}_moco_nulled.nii\n",
    "3dUpsample -overwrite  -datum short -prefix ${base}_BOLD_intemp.nii   -n 2 -input ${base}_moco_notnulled.nii\n",
    "\n",
    "##for Magentom clasical VASO sequence\n",
    "NumVol=`3dinfo -nv ${base}_Nulled_intemp.nii`\n",
    "3dTcat -overwrite -prefix ${base}_Nulled_intemp.nii ${base}_Nulled_intemp.nii'[0]' ${base}_Nulled_intemp.nii'[0..'`expr $NumVol - 2`']'\n",
    "\n",
    "echo \"I am correcting for the proper TR in the header\"\n",
    "3drefit -TR 1.9295 ${base}_BOLD_intemp.nii\n",
    "3drefit -TR 1.9295 ${base}_Nulled_intemp.nii\n",
    "\n",
    "echo \"BOLD correction happens now\"\n",
    "LN_BOCO -Nulled ${base}_Nulled_intemp.nii -BOLD ${base}_BOLD_intemp.nii -output ${base}\n",
    "\n",
    "#\"calculating Mean and tSNR maps\"\n",
    "#3dTstat -mean -prefix ${base}_mean_nulled.nii ${base}_moco_nulled.nii -overwrite\n",
    "#3dTstat -mean -prefix ${base}_mean_notnulled.nii ${base}_moco_notnulled.nii -overwrite\n",
    "#3dTstat  -overwrite -mean  -prefix ${base}_BOLD.Mean.nii ${base}_BOLD_intemp.nii'[1..$]'\n",
    "#3dTstat  -overwrite -cvarinv  -prefix ${base}_BOLD.tSNR.nii ${base}_BOLD_intemp.nii'[1..$]'\n",
    "#3dTstat  -overwrite -mean  -prefix ${base}_VASO.Mean.nii ${base}_VASO_LN.nii'[1..$]'\n",
    "#3dTstat  -overwrite -cvarinv -prefix ${base}_VASO.tSNR.nii ${base}_VASO_LN.nii'[1..$]'\n",
    "\n",
    "echo \"calculating T1 in EPI space\"\n",
    "3dTcat -prefix combined.nii  ${base}_moco_nulled.nii ${base}_moco_notnulled.nii -overwrite\n",
    "3dTstat -cvarinv -overwrite  -prefix ${base}_T1w.nii combined.nii\n",
    "rm combined.nii\n",
    "#3dcalc -a mean_nulled.nii -b mean_notnulled.nii -expr 'abs(b-a)/(a+b)' -prefix T1w.nii -overwrite\n",
    "\n",
    "echo \"curtosis and skew\"\n",
    "LN_SKEW -input ${base}_BOLD_intemp.nii\n",
    "LN_SKEW -input ${base}_VASO_LN.nii\n",
    "\n",
    "# The FSL GLM does not seem to like images where values are between 0 and 1. There fore, we are multipolying everything by 100.\n",
    "fslmaths ${base}_VASO_LN.nii -mul 100 ${base}_VASO_LN_short.nii -odt short\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean image, tSNR, skew and kurtosis\n",
    "\n",
    "in this [blog-post](https://layerfmri.com/2020/04/06/qa/), Renzo describes different measures of quality assessment for layer fMRI.\n",
    "\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "This process uses a mask containing the postcentral gyrus plus a lot of other stuff. Therefore, it can be made more precise by using a GM-mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['mean', 'tSNR','skew','kurt']\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    for measure in \n",
    "    for modality in ['BOLD_intemp', 'VASO_LN']:\n",
    "        data = nb.load('/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-02/func/rest/sub-02_rest3b_run-001_VASO_LN_tSNR.nii').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "measures = ['mean', 'tSNR']\n",
    "colorMaps = [cm.Greys_r,'hot']\n",
    "\n",
    "\n",
    "\n",
    "for modality in ['BOLD_intemp', 'VASO_LN']:\n",
    "    for measure,colorMap in zip(measures, colorMaps):\n",
    "        fig, axes = plt.subplots(len(subs), 1, figsize=(5,40), sharex=True, sharey=True)\n",
    "\n",
    "        for sub,k in zip(subs,range(len(subs))):\n",
    "            data = nb.load(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/func/rest/{sub}_rest3b_run-001_{modality}_{measure}.nii').get_fdata()\n",
    "            data = data[:,:,10,0]\n",
    "            rotated_img = ndimage.rotate(data, 90)\n",
    "            im = axes[k].imshow(rotated_img, cmap=colorMap)\n",
    "            plt.axis('off')\n",
    "            #plt.colorbar()\n",
    "            #fig.colorbar(rotated_img, ax=axes[k])\n",
    "            axes[k].axis('off')\n",
    "            if measure == 'tSNR':\n",
    "                cbar = fig.colorbar(im,ax=axes[k], ticks=[rotated_img.min(), rotated_img.max()])\n",
    "                cbar.ax.tick_params(size=0)\n",
    "                \n",
    "        plt.savefig(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/qualityAssessment/{modality}_{measure}_map', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "measures = ['skew','kurt']\n",
    "colorMaps = [cm.Greys_r, cm.Greys_r]\n",
    "\n",
    "\n",
    "\n",
    "for modality in ['BOLD_intemp', 'VASO_LN']:\n",
    "    for measure,colorMap in zip(measures, colorMaps):\n",
    "        fig, axes = plt.subplots(len(subs), 1, figsize=(5,40), sharex=True, sharey=True)\n",
    "\n",
    "        for sub,k in zip(subs,range(len(subs))):\n",
    "            data = nb.load(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/func/rest/{sub}_rest3b_run-001_{modality}_{measure}.nii').get_fdata()\n",
    "            data = data[:,:,10,0]\n",
    "            rotated_img = ndimage.rotate(data, 90)\n",
    "            #plt.colorbar()\n",
    "            #fig.colorbar(rotated_img, ax=axes[k])\n",
    "            axes[k].axis('off')\n",
    "\n",
    "            im = axes[k].imshow(rotated_img, cmap=colorMap, vmin = -1, vmax = 1)\n",
    "            \n",
    "\n",
    "            cbar = fig.colorbar(im,ax=axes[k], ticks=[-1, 1])\n",
    "            cbar.ax.tick_params(size=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        plt.savefig(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/qualityAssessment/{modality}_{measure}_map', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subList = []\n",
    "valList = []\n",
    "modalityList = []\n",
    "measureList = []\n",
    "\n",
    "\n",
    "for sub in subs:\n",
    "    for modality in ['BOLD_intemp', 'VASO_LN']:\n",
    "        \n",
    "        for measure in ['tSNR','skew','kurt']:\n",
    "\n",
    "            data = nb.load(root + f'/derivatives/{sub}/func/rest/{sub}_rest3b_run-001_{modality}_{measure}.nii').get_fdata()\n",
    "\n",
    "\n",
    "            mask = nb.load(root + f'/derivatives/{sub}/{sub}_moma.nii').get_fdata()\n",
    "\n",
    "            data_masked = np.multiply(data[:,:,:,0], mask)[np.multiply(data[:,:,:,0], mask)!=0]\n",
    "\n",
    "\n",
    "            subList.append([str(sub) for i in range(len(data_masked))])\n",
    "            modalityList.append([str(modality) for i in range(len(data_masked))])\n",
    "            measureList.append([str(measure) for i in range(len(data_masked))])\n",
    "            valList.append(data_masked)\n",
    "\n",
    "subList = [item for sublist in subList for item in sublist]\n",
    "modalityList = [item for sublist in modalityList for item in sublist]\n",
    "measureList = [item for sublist in measureList for item in sublist]\n",
    "valList = [item for sublist in valList for item in sublist]\n",
    "\n",
    "\n",
    "subList = np.array(subList).flatten()\n",
    "subList = subList.reshape((subList.size,-1)) \n",
    "\n",
    "valList = np.array(valList).flatten()\n",
    "valList = valList.reshape((valList.size,-1)) \n",
    "\n",
    "measureList = np.array(measureList).flatten()\n",
    "measureList = measureList.reshape((measureList.size,-1)) \n",
    "\n",
    "modalityList = np.array(modalityList).flatten()\n",
    "modalityList = modalityList.reshape((modalityList.size,-1)) \n",
    "    \n",
    "\n",
    "QA = pd.DataFrame({'subject': subList[:,0], 'val': valList[:,0], 'measure': measureList[:,0], 'modality': modalityList[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_line(data, var=None, **kws):\n",
    "    \n",
    "    # If no variable provided skip adding mean line\n",
    "    if not var: return\n",
    "    \n",
    "    #Calculate mean for each group\n",
    "    m = np.mean(data[var])\n",
    "    \n",
    "    #Get current axis\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    #add line at group mean\n",
    "    ax.axvline(m, color='black', lw=2, ls='--')\n",
    "    \n",
    "    #annotate group mean\n",
    "    #x_pos=0.65\n",
    "    #if m > 5000: x_pos=0.2\n",
    "    #ax.text(x_pos, 0.7, f'mean={m:.0f}', \n",
    "    #        transform=ax.transAxes,   #transforms positions to range from (0,0) to (1,1)\n",
    "    #        color='maroon', fontweight='bold', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(QA.loc[(QA['measure']=='tSNR')], row='subject',hue='modality')\n",
    "g.map_dataframe(sns.kdeplot, \"val\", fill=True)\n",
    "g.map_dataframe(add_mean_line, var='val')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['tSNR','skew','kurt']\n",
    "\n",
    "\n",
    "for measure,n in zip(measures, range(len(measures))):\n",
    "    fig, axes = plt.subplots(len(subs), 1, figsize=(5,40), sharex=True, sharey=True)\n",
    "\n",
    "    for sub,k in zip(subs,range(len(subs))):\n",
    "            sns.kdeplot(ax = axes[k], data= QA.loc[(QA['measure']==measure)&(QA['subject']==sub)], x=\"val\", hue='modality', fill=True)           \n",
    "            #axes[0].set_title(f'{measure}', fontsize=24)\n",
    "            axes[-1].set_xlabel(f'{measure}', fontsize=20)\n",
    "            if measure != 'tSNR':\n",
    "                axes[0].set_xlim(-1,1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    plt.savefig(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/qualityAssessment/{measure}', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute framewise displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_FD = []\n",
    "timepoints = []\n",
    "subjects=[]\n",
    "mods = []\n",
    "\n",
    "for sub in subs:\n",
    "    \n",
    "    for modality in modalities:\n",
    "        \n",
    "        TX = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"TX\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "        TY = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"TY\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "        TZ = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"TZ\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "\n",
    "        RX = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"RX\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "        RY = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"RY\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "        RZ = pd_ses['Motion'].loc[(pd_ses['Motion_Name'].str.contains(\"RZ\") == 1)&(pd_ses['subject']==sub)&(pd_ses['modality']==modalitiesDict[modality])].tolist()\n",
    "\n",
    "        for n in range(len(TX)-1):\n",
    "            FD_trial = abs(TX[n]-TX[n+1])+abs(TY[n]-TY[n+1])+abs(TZ[n]-TZ[n+1])+abs((50*RX[n])-(50*RX[n+1]))+abs((50*RY[n])-(50*RY[n+1]))+abs((50*RZ[n])-(50*RZ[n+1]))\n",
    "            sub_FD.append(FD_trial)\n",
    "            timepoints.append(n)\n",
    "            subjects.append(sub)\n",
    "            mods.append(modalitiesDict[modality])\n",
    "        \n",
    "\n",
    "FDs = pd.DataFrame({'subject':subjects, 'volume':timepoints, 'FD':sub_FD, 'modality': mods})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"tab10\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(subs), 1, figsize=(5,40), sharex=True, sharey=True)\n",
    "\n",
    "for sub,k in zip(subs,range(len(subs))):\n",
    "        sns.violinplot(ax = axes[k], data= FDs.loc[FDs['subject']==sub], inner = 'quartile', x='subject',y='FD', hue='modality', split=True, alpha = 0.5, palette = [sns.color_palette(\"tab10\")[1], sns.color_palette(\"tab10\")[0]])           \n",
    "        axes[-1].set_xlabel(f'Framewise discplacement', fontsize=20)\n",
    "        axes[k].set_ylabel(f'FD (mm)', fontsize=20)\n",
    "        \n",
    "        if not k == len(subs):\n",
    "            axes[k].set_xticks([])\n",
    "            axes[k].set_xlabel('')\n",
    "        \n",
    "        #if not k == len(subs):\n",
    "         #   axes[k].legend([],[], frameon=False)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/qualityAssessment/FDs', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.figure(figsize=(12,8))\n",
    "plt.title('Framewise Displacements (rest)', fontsize=24)\n",
    "\n",
    "sns.violinplot(x='subject',y='FD',data=FDs, hue = 'modality')\n",
    "plt.ylabel(\"FD (mm)\", fontsize=20)\n",
    "plt.xlabel(\"participant\", fontsize=20)\n",
    "\n",
    "# plt.savefig('/home/sebastian/Desktop/resting_state_FD.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(subs), 1,sharex=True,sharey=True, figsize = (20,10))\n",
    "\n",
    "for sub,n in zip(subs,range(len(subs))):\n",
    "    sns.lineplot(ax = axes[n], x='volume',y='FD',data=FDs.loc[FDs['subject']==sub],hue = 'modality')\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('/home/sebastian/Desktop/resting_state_FD_subplots.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.figure(figsize=(12,8))\n",
    "plt.title('Framewise Displacements')\n",
    "\n",
    "sns.violinplot(x='subject',y='FD',data=FDs, inner=\"stick\")\n",
    "plt.ylabel(\"FD (mm)\")\n",
    "\n",
    "plt.savefig('/home/sebastian/Desktop/resting_state_FD.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-transforming motion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subs:\n",
    "    TX_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='TX')&(pd_ses['subject']==sub)])\n",
    "    TY_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='TY')&(pd_ses['subject']==sub)])\n",
    "    TZ_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='TZ')&(pd_ses['subject']==sub)])\n",
    "\n",
    "    RX_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='RX')&(pd_ses['subject']==sub)])\n",
    "    RY_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='RY')&(pd_ses['subject']==sub)])\n",
    "    RZ_Z = stats.zscore(pd_ses['Motion'].loc[(pd_ses['Motion_Name']=='RZ')&(pd_ses['subject']==sub)])\n",
    "    \n",
    "    TX_Z_new = []\n",
    "    TY_Z_new = []\n",
    "    TZ_Z_new = []\n",
    "    \n",
    "    RX_Z_new = []\n",
    "    RY_Z_new = []\n",
    "    RZ_Z_new = []\n",
    "\n",
    "    for n in range(len(TX_Z)):\n",
    "        TX_Z_new.append(TX_Z[n])\n",
    "        TX_Z_new.append((TX_Z[n]+TX_Z[n])/2)\n",
    "        \n",
    "        TY_Z_new.append(TY_Z[n])\n",
    "        TY_Z_new.append((TY_Z[n]+TY_Z[n])/2)\n",
    "        \n",
    "        TZ_Z_new.append(TZ_Z[n])\n",
    "        TZ_Z_new.append((TZ_Z[n]+TZ_Z[n])/2)\n",
    "        \n",
    "        \n",
    "        RX_Z_new.append(RX_Z[n])\n",
    "        RX_Z_new.append((RX_Z[n]+RX_Z[n])/2)\n",
    "        \n",
    "        RY_Z_new.append(RY_Z[n])\n",
    "        RY_Z_new.append((RY_Z[n]+RY_Z[n])/2)\n",
    "        \n",
    "        RZ_Z_new.append(RZ_Z[n])\n",
    "        RZ_Z_new.append((RZ_Z[n]+RZ_Z[n])/2)\n",
    "    \n",
    "    sub_motion_matrix = pd.DataFrame({'TX_Z':TX_Z_new, 'TY_Z':TY_Z_new, 'TZ_Z':TZ_Z_new, 'RX_Z':RX_Z_new, 'RY_Z':RY_Z_new, 'RZ_Z':RZ_Z_new})\n",
    "    sub_motion_matrix.to_csv( '/media/sebastian/elements/data/s1_anfunco_analysis/%s/func/vaso/rest_3b/motion/%s_motionparams.txt'%(sub,sub), header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved file\n",
    "\n",
    "sub_motion_matrix = pd.read_csv('/media/sebastian/elements/data/s1_anfunco_analysis/sub05/func/vaso/rest_3b/motion/sub05_motionparams.txt', header=None,  sep=' ') \n",
    "# Preview the first 5 lines of the loaded data \n",
    "sub_motion_matrix.columns = ['TX_Z', 'TY_Z', 'TZ_Z', 'RX_Z', 'RY_Z', 'RZ_Z']\n",
    "\n",
    "sub_motion_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_Z_new = []\n",
    "\n",
    "for n in range(len(TX_Z)):\n",
    "    TX_Z_new.append(TX_Z[n])\n",
    "    TX_Z_new.append((TX_Z[n]+TX_Z[n])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TX_Z_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "f = interpolate.interp2d(TX_Z, kind='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TX_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomical processing\n",
    "\n",
    "\n",
    "### Averaging of the 3 high resolution slabs using ITK-SNAP\n",
    "\n",
    "To increase the SNR, I first averaged the 3 high resolution slabs we acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/media/sebastian/Data/S1ANFUNCO/raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "restRuns = sorted(glob.glob(root + '/S1ANFUNCO_BIDS/sub-*/ses-00*/func/sub-*_ses-00*_task-rest*_cbv.nii.gz'))\n",
    "subList = [i[-47:-41] for i in restRuns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subList[1:]:\n",
    "    \n",
    "    # Define output folder\n",
    "    outFolder = f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/anat'\n",
    "    \n",
    "    # look for 3 anatomical images.\n",
    "    imgs = sorted(glob.glob(root + f'S1ANFUNCO_BIDS/{sub}/ses-00*/anat/*_ses-00*_highres-mp2rage_run-00*_uni.nii.gz'))\n",
    "    \n",
    "    # Read reference image.\n",
    "    fixed = ants.image_read(imgs[0])\n",
    "    \n",
    "    # Save it for easy processing in a step below\n",
    "    ants.image_write(fixed, outFolder + f'/1.nii', ri=False)\n",
    "    \n",
    "    # Register images 2 and 3\n",
    "    for img,n in zip(imgs[1:],range(2,len(imgs)+1)):\n",
    "        \n",
    "        moving = ants.image_read(img)\n",
    "        mytx = ants.registration(fixed=fixed , moving=moving, type_of_transform='Rigid' )\n",
    "        warped_moving = mytx['warpedmovout']\n",
    "        \n",
    "        # Save it for easy processing in a step below\n",
    "        ants.image_write(warped_moving, outFolder + f'/{n}.nii', ri=False)\n",
    "    \n",
    "    # Load 3 anatomical images for averaging\n",
    "    img1 = nb.load(outFolder + f'/1.nii').get_fdata()\n",
    "    img2 = nb.load(outFolder + f'/2.nii').get_fdata()\n",
    "    img3 = nb.load(outFolder + f'/3.nii').get_fdata()\n",
    "\n",
    "    # Average 3 anatomical images to increase SNR\n",
    "    avg = np.add(img1, img2)\n",
    "    avg = np.add(avg, img3)\n",
    "    avg = np.divide(avg, 3)\n",
    "    ni_img = nb.Nifti1Image(avg, nb.load(outFolder + f'/1.nii').affine)\n",
    "    nb.save(ni_img, outFolder+ f'/{sub}_highres-mp2rage_uni_average.nii')\n",
    "    \n",
    "    # Bias field correction\n",
    "    image = ants.image_read(outFolder+ f'/{sub}_highres-mp2rage_uni_average.nii')\n",
    "    image_n4 = ants.n4_bias_field_correction(image)\n",
    "    \n",
    "    # Save corrected image\n",
    "    ants.image_write(image_n4, outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected.nii', ri=False)\n",
    "    \n",
    "    # Delete intermediate steps.\n",
    "    for n in range(1,len(imgs)+1):\n",
    "        os.remove(outFolder + f\"/{n}.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sub-02 the acquisition of anatomical data was a bit messy due to the various sessions, \n",
    "# therefore I will do it manually here.\n",
    "\n",
    "outFolder = f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/sub-02/anat'\n",
    "\n",
    "# Bias field correction\n",
    "image = ants.image_read(outFolder+ f'/sub-02_highres-mp2rage_uni_average.nii.gz')\n",
    "image_n4 = ants.n4_bias_field_correction(image)\n",
    "    \n",
    "# Save corrected image\n",
    "ants.image_write(image_n4, outFolder+ f'/sub-02_highres-mp2rage_uni_average_N4corrected.nii', ri=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel reduction\n",
    "\n",
    "Because we are only interested in the postcentral gyrus, we will reduce our voxels with several measures.\n",
    "First, we will use brain masks and then crop our data.\n",
    "\n",
    "#### Brain mask\n",
    "\n",
    "Automatic brain extraction is often problematic. Therefore, I manually drew outlines of the brain in every 3rd slice and dilated them with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subList:\n",
    "    outFolder = f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/anat'\n",
    "    # load data\n",
    "    nii = load(outFolder + f'/{sub}_highres-mp2rage_uni_average_N4corrected_brainMask.nii.gz')\n",
    "\n",
    "    basename = nii.get_filename().split(os.extsep, 1)[0]\n",
    "    dirname = os.path.dirname(nii.get_filename())\n",
    "    data = nii.get_fdata()\n",
    "\n",
    "    # perform closing\n",
    "    data = morphology.binary_dilation(data, iterations=3)\n",
    "    data = morphology.binary_erosion(data, iterations=3)\n",
    "\n",
    "    # perform opening\n",
    "    #data = morphology.binary_erosion(data, iterations=1)\n",
    "    #data = morphology.binary_dilation(data, iterations=1)\n",
    "\n",
    "    # save as nifti\n",
    "    out = Nifti1Image(data, header=nii.header, affine=nii.affine)\n",
    "    save(out, basename + \"_opening_closing.nii.gz\")\n",
    "\n",
    "\n",
    "    print('Morphology operations are done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can multiply the anatomical image with the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subList:\n",
    "    outFolder = f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/anat'\n",
    "    anatData = nb.load(outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected.nii').get_fdata()\n",
    "    maskData = nb.load(outFolder + f'/{sub}_highres-mp2rage_uni_average_N4corrected_brainMask_opening_closing.nii.gz').get_fdata()\n",
    "    \n",
    "    # Multiply with binary brain mask to get rid of non-brain voxels.\n",
    "    masekdData = np.multiply(anatData, maskData)\n",
    "    \n",
    "    # save as nifti\n",
    "    ni_img = nb.Nifti1Image(masekdData, nb.load(outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected.nii').affine)\n",
    "    nb.save(ni_img, outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected_brain.nii')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping\n",
    "\n",
    "To further reduce our voxels, we copped the data to our area of interest. This involved some visual inspection. The coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundariesDict = {'sub-02': [80, 170, 75, 115, 5, 51],\n",
    "                  'sub-05': [110, 160, 60, 125, 7, 47],\n",
    "                  'sub-06': [100, 160, 70, 90, 9, 46],\n",
    "                  'sub-07': [100, 180, 70, 120, 10, 45],\n",
    "                  'sub-09': [75, 175, 110, 90, 7, 47],\n",
    "                  'sub-10': [90, 175, 80, 100, 9, 45],\n",
    "                  'sub-12': [90, 175, 60, 110, 4, 48],\n",
    "                  'sub-15': [85, 165, 80, 110, 4, 49],\n",
    "                  'sub-16': [90, 160, 65, 125, 4, 51],\n",
    "                  'sub-17': [80, 155, 95, 115, 4, 48],\n",
    "                  'sub-18': [65, 170, 90, 115, 4, 51]\n",
    "                 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import ExtractROI\n",
    "\n",
    "for sub in subList:\n",
    "    outFolder = f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/anat'\n",
    "\n",
    "    anatFile = outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected_brain.nii'\n",
    "\n",
    "    # Apparently, the fslroi wrapper in nipype wants an existing file as output filename (?). Therefore, I will create one with the same dimensions.\n",
    "    tmpFile = nb.load(anatFile)\n",
    "    tmp = Nifti1Image(tmpFile.get_fdata(), header=tmpFile.header, affine=tmpFile.affine)\n",
    "    save(tmp, outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz')\n",
    "\n",
    "\n",
    "    fslroi = ExtractROI(in_file=anatFile, roi_file= outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz', \n",
    "                        x_min = boundariesDict[sub][0], x_size = boundariesDict[sub][1], \n",
    "                        y_min = boundariesDict[sub][2], y_size = boundariesDict[sub][3],\n",
    "                        z_min = boundariesDict[sub][4], z_size = boundariesDict[sub][5]\n",
    "                       )\n",
    "\n",
    "    out = fslroi.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "We started the segmentation process with an automatic segmentation using FSL FAST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "for sub in sublistLim:\n",
    "    fastr = fsl.FAST()\n",
    "    fastr.inputs.in_files = outFolder+ f'/{sub}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz'\n",
    "    out = fastr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmetntation was then manually corrected and saved as\n",
    "\n",
    "'{sub}_highres-mp2rage_uni_average_N4corrected_brain_trunc_pveseg_corrected.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import afni\n",
    "\n",
    "for sub in subList:\n",
    "    inputFiles = sorted(glob.glob(f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/func/*/{sub}_*_run-00*_moco_*ulled.nii'))\n",
    "    tcat = afni.TCat()\n",
    "    tcat.inputs.in_files = inputFiles\n",
    "    tcat.inputs.out_file= f'/media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/{sub}/func/combined.nii'\n",
    "\n",
    "    res = tcat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subList)}\"\n",
    "\n",
    "List1=$1\n",
    "\n",
    "subsList=($List1)\n",
    "\n",
    "len=${#subsList[@]}\n",
    " \n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "echo Current subject: ${subsList[$j]}\n",
    "\n",
    "cd /media/sebastian/Data/S1ANFUNCO/raw_data/derivatives/${subsList[$j]}/func\n",
    "\n",
    "3dTstat -cvarinv -overwrite -prefix ${subsList[$j]}_EPI_T1w.nii combined.nii\n",
    "rm combined.nii\n",
    "\n",
    "N4BiasFieldCorrection -d 3 -i ${subsList[$j]}_EPI_T1w.nii -o ${subsList[$j]}_EPI_T1w_N4Corrected.nii\n",
    "\n",
    "\n",
    "echo \"Upsampling\"\n",
    "delta_x=$(3dinfo -di ${subsList[$j]}_EPI_T1w_N4Corrected.nii)\n",
    "delta_y=$(3dinfo -dj ${subsList[$j]}_EPI_T1w_N4Corrected.nii)\n",
    "delta_z=$(3dinfo -dk ${subsList[$j]}_EPI_T1w_N4Corrected.nii)\n",
    "sdelta_x=$(echo \"((sqrt($delta_x * $delta_x) / 5))\"|bc -l)\n",
    "sdelta_y=$(echo \"((sqrt($delta_y * $delta_y) / 5))\"|bc -l)\n",
    "sdelta_z=$(echo \"((sqrt($delta_z * $delta_z) / 1))\"|bc -l)\n",
    "# here I only upscale in 2 dimensions.\n",
    "\n",
    "3dresample -dxyz $sdelta_x $sdelta_y $sdelta_z -rmode Cu -overwrite -prefix ${subsList[$j]}_EPI_T1w_N4Corrected_scaled.nii -input ${subsList[$j]}_EPI_T1w_N4Corrected.nii\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration\n",
    "\n",
    "For the registration, I manually matched the average UNI images with the upsampled anatomy in EPI space. The resulting matrix was saved as \"initial_matrix\".\n",
    "\n",
    "To further improve our registration, we will use a registration mask. Fortunately, we happen to have one already from the initial motion correction. We just have to upsample it so it machtes out target space.\n",
    "\n",
    "We'll do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"$root\"\n",
    "\n",
    "for sub in $1\n",
    "do\n",
    "cd $2/derivatives/$sub\n",
    "\n",
    "echo Upsampling $sub moma\n",
    "delta_x=$(3dinfo -di \"$sub\"_moma.nii)\n",
    "delta_y=$(3dinfo -dj \"$sub\"_moma.nii)\n",
    "delta_z=$(3dinfo -dk \"$sub\"_moma.nii)\n",
    "sdelta_x=$(echo \"((sqrt($delta_x * $delta_x) / 5))\"|bc -l)\n",
    "sdelta_y=$(echo \"((sqrt($delta_y * $delta_y) / 5))\"|bc -l)\n",
    "sdelta_z=$(echo \"((sqrt($delta_z * $delta_z) / 1))\"|bc -l)\n",
    "# here I only upscale in 2 dimensions.\n",
    "\n",
    "3dresample -dxyz $sdelta_x $sdelta_y $sdelta_z -rmode Cu -overwrite -prefix \"$sub\"_moma_scaled.nii -input \"$sub\"_moma.nii\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"{\" \".join(subList)}\" \"$root\"\n",
    "\n",
    "List1=$1\n",
    "\n",
    "subsList=($List1)\n",
    "\n",
    "len=${#subsList[@]}\n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "cd $2/derivatives/${subsList[$j]}/anat/registration\n",
    "\n",
    "echo Current participant: ${subsList[$j]}\n",
    "echo Fixed: $2/derivatives/${subsList[$j]}/func/${subsList[$j]}_EPI_T1w_N4Corrected_scaled.nii\n",
    "echo Moving: ../${subsList[$j]}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz\n",
    "echo ###\n",
    "\n",
    "antsRegistration \\\n",
    "--verbose 1 \\\n",
    "--dimensionality 3  \\\n",
    "--float 0  \\\n",
    "--collapse-output-transforms 1  \\\n",
    "--interpolation BSpline[5] \\\n",
    "--output [registered1_,registered1_Warped.nii,1]  \\\n",
    "--use-histogram-matching 0  \\\n",
    "--winsorize-image-intensities [0.005,0.995]  \\\n",
    "--initial-moving-transform initial_matrix.txt \\\n",
    "--transform SyN[0.1,3,0]  \\\n",
    "--metric CC[$2/derivatives/${subsList[$j]}/func/${subsList[$j]}_EPI_T1w_N4Corrected_scaled.nii, ../${subsList[$j]}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz,1,2]  \\\n",
    "--convergence [60x10,1e-6,10]  \\\n",
    "--shrink-factors 2x1  \\\n",
    "--smoothing-sigmas 1x0vox  \\\n",
    "-x ../../${subsList[$j]}_moma_scaled.nii\n",
    "\n",
    "antsApplyTransforms \\\n",
    "--interpolation BSpline[5] \\\n",
    "-d 3 -i ../${subsList[$j]}_highres-mp2rage_uni_average_N4corrected_brain_trunc.nii.gz \\\n",
    "-r $2/derivatives/${subsList[$j]}/func/${subsList[$j]}_EPI_T1w_N4Corrected_scaled.nii \\\n",
    "-t registered1_1Warp.nii.gz \\\n",
    "-t registered1_0GenericAffine.mat \\\n",
    "-o ${subsList[$j]}_highres-mp2rage_uni_average_N4corrected_brain_trunc_registered.nii\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{\" \".join(subs)}\" \"{\" \".join(outFolders)}\"\n",
    "\n",
    "\n",
    "List1=$1\n",
    "List2=$2\n",
    "\n",
    "subsList=($List1)\n",
    "outFolders=($List2)\n",
    "\n",
    "\n",
    "len=${#subsList[@]}\n",
    "\n",
    "\n",
    "imageTypes=(\"n\" \"nn\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for (( j=0; j<$len; j++ ))\n",
    "do\n",
    "\n",
    "# base=${subsList[$j]}_rest3b\n",
    "base=${subsList[$j]}_rest3b_run-001\n",
    "outFolder=${outFolders[$j]}\n",
    "echo Current subject: ${subsList[$j]}\n",
    "echo The output will be saved here: ${outFolder}\n",
    "echo The basename of the output is: ${base}\n",
    "echo #\n",
    "echo #\n",
    "echo #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
